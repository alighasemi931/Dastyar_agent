# scripts/fetch_full_product_data_orm.py
import requests
import json
import time
from sqlalchemy.orm import Session
from sqlalchemy import inspect
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from databases.database import SessionLocal, engine
from models.model import Base, IPHONE_PRODUCTS, WATCH_PRODUCTS, IPHONE_COLORS, WATCH_COLORS

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept": "application/json"
}

IPHONE_API = "https://api.digikala.com/v1/categories/mobile-phone/brands/apple/search/"
WATCH_API = "https://api.digikala.com/v1/categories/smart-watch/brands/apple/search/"
IPHONE_DETAILS_API = "https://api.digikala.com/v2/product/"
WATCH_DETAILS_API = "https://api.digikala.com/v2/product/"
IPHONE_REVIEWS_API = "https://api.digikala.com/v1/rate-review/products/"
WATCH_REVIEWS_API = "https://api.digikala.com/v1/rate-review/products/"

# ==========================
# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† Ø®ÙˆØ§Ù†Ø§ Ø§Ø² Ù†Ø¸Ø±Ø§Øª
# ==========================
def build_readable_reviews(comments):
    lines = []
    for i, comment in enumerate(comments, 1):
        rate = comment.get("rate", "")
        body = comment.get("body", "").strip()
        user_type = "ğŸ›’ Ø®Ø±ÛŒØ¯Ø§Ø±" if comment.get("review_user_type") == "buyer" else "ğŸ‘¤ Ú©Ø§Ø±Ø¨Ø±"
        lines.append(f"{i}. {user_type} | Ø§Ù…ØªÛŒØ§Ø²: {rate}\n{body}\n")
    return "\n".join(lines) if lines else "Ø¨Ø¯ÙˆÙ† Ù†Ø¸Ø± Ø«Ø¨Øªâ€ŒØ´Ø¯Ù‡."

# ==========================
# Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ† Ø¯Ø± Ø¬Ø¯ÙˆÙ„
# ==========================
def ensure_column(model, column_name):
    inspector = inspect(engine)
    columns = [col["name"] for col in inspector.get_columns(model.__tablename__)]
    if column_name not in columns:
        print(f"âš ï¸ Ø³ØªÙˆÙ† {column_name} Ø¯Ø± Ø¬Ø¯ÙˆÙ„ {model.__tablename__} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        print(f"â„¹ï¸ Ø³ØªÙˆÙ† {column_name} Ø¯Ø± Ø¬Ø¯ÙˆÙ„ {model.__tablename__} Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.")

# ==========================
# Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø±Ù†Ú¯â€ŒÙ‡Ø§
# ==========================
def fetch_and_store_products(api_url, product_model, color_model, max_pages=2):
    session: Session = SessionLocal()
    total_added = 0

    for page in range(1, max_pages + 1):
        url = f"{api_url}?page={page}"
        try:
            r = requests.get(url, headers=HEADERS, timeout=10)
            r.raise_for_status()
            data = r.json()
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            products_list = []
            data_content = data.get("data", {})
            if isinstance(data_content, dict):
                products_list = data_content.get("products", [])
            elif isinstance(data_content, list):
                products_list = data_content

            if not products_list:
                break

            for p in products_list:
                pid = p.get("id")
                title_fa = p.get("title_fa")
                relative_url = p.get("url", {}).get("uri") if isinstance(p.get("url"), dict) else None

                selling_price = None
                default_variant = p.get("default_variant")
                if isinstance(default_variant, dict):
                    selling_price = default_variant.get("price", {}).get("selling_price")
                elif isinstance(default_variant, list) and len(default_variant) > 0:
                    selling_price = default_variant[0].get("price", {}).get("selling_price")

                if not (pid and title_fa and relative_url and selling_price):
                    continue

                # Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØµÙˆÙ„
                db_product = session.query(product_model).filter_by(product_id=pid).first()
                if not db_product:
                    db_product = product_model(
                        product_id=pid,
                        title_fa=title_fa,
                        relative_url=f"https://www.digikala.com{relative_url}",
                        selling_price=selling_price
                    )
                    session.add(db_product)
                    total_added += 1
                else:
                    db_product.title_fa = title_fa
                    db_product.relative_url = f"https://www.digikala.com{relative_url}"
                    db_product.selling_price = selling_price

                # Ø°Ø®ÛŒØ±Ù‡ Ø±Ù†Ú¯â€ŒÙ‡Ø§
                colors = p.get("colors", [])
                for c in colors:
                    color_title = c.get("title")
                    if color_title and not session.query(color_model).filter_by(product_id=pid, title=color_title).first():
                        session.add(color_model(product_id=pid, title=color_title))
            
            session.commit()
            print(f"âœ… ØµÙØ­Ù‡ {page} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯. Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡: {total_added}")
            time.sleep(1)

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØµÙØ­Ù‡ {page}: {e}")
            session.rollback()
    session.close()
    print(f"âœ¨ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª. Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯: {total_added}")

# ==========================
# Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø´Ø®ØµØ§Øª Ùˆ Ù†Ø¸Ø±Ø§Øª
# ==========================
def fetch_full_product_data(product_model, color_model, details_api, reviews_api, delay_specs=1, delay_reviews=1, max_pages=2):
    session: Session = SessionLocal()
    products = session.query(product_model).all()
    print(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´: {len(products)}")

    for idx, product in enumerate(products, start=1):
        pid = product.product_id
        print(f"\n({idx}/{len(products)}) Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {pid} ...")

        # Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„
        try:
            r = requests.get(f"{details_api}{pid}/", headers=HEADERS, timeout=10)
            r.raise_for_status()
            data = r.json()

            # Ø°Ø®ÛŒØ±Ù‡ Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø§Ø² Ø¬Ø²Ø¦ÛŒØ§Øª
            colors = data.get("data", {}).get("product", {}).get("colors", [])
            for c in colors:
                title = c.get("title")
                if title and not session.query(color_model).filter_by(product_id=pid, title=title).first():
                    session.add(color_model(product_id=pid, title=title))
            session.commit()

            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø´Ø®ØµØ§Øª
            specs = data.get("data", {}).get("product", {}).get("specifications", [])
            if specs and getattr(product, "specifications", None) in (None, ""):
                product.specifications = json.dumps(specs, ensure_ascii=False)
                session.commit()
                print(f"âœ… Ù…Ø´Ø®ØµØ§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
            time.sleep(delay_specs)

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ {pid}: {e}")
            session.rollback()

        # Ø¯Ø±ÛŒØ§ÙØª Ù†Ø¸Ø±Ø§Øª
        try:
            all_comments = []
            for page in range(1, max_pages + 1):
                url = f"{reviews_api}{pid}/?sort=buyers&page={page}"
                r = requests.get(url, headers=HEADERS, timeout=10)
                r.raise_for_status()
                comments = r.json().get("data", {}).get("comments", [])
                if not comments:
                    break
                all_comments.extend(comments)
                time.sleep(0.5)

            product.reviews_text = build_readable_reviews(all_comments)
            session.commit()
            print(f"ğŸ’¾ Ù†Ø¸Ø±Ø§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ ({len(all_comments)} Ù†Ø¸Ø±).")
            time.sleep(delay_reviews)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ø°Ø®ÛŒØ±Ù‡ Ù†Ø¸Ø±Ø§Øª Ù…Ø­ØµÙˆÙ„ {pid}: {e}")
            session.rollback()

    session.close()
    print("\nâœ¨ Ø¹Ù…Ù„ÛŒØ§Øª Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.")

# ==========================
# Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
# ==========================
if __name__ == "__main__":
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
    Base.metadata.create_all(engine)
    print("âœ… Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù†Ø¯ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ†Ø¯).")

    # Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
    ensure_column(IPHONE_PRODUCTS, "specifications")
    ensure_column(IPHONE_PRODUCTS, "reviews_text")
    ensure_column(WATCH_PRODUCTS, "specifications")
    ensure_column(WATCH_PRODUCTS, "reviews_text")

    # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø±Ù†Ú¯â€ŒÙ‡Ø§
    print("\n=== Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¢ÛŒÙÙˆÙ† ===")
    fetch_and_store_products(IPHONE_API, IPHONE_PRODUCTS, IPHONE_COLORS, max_pages=2)

    print("\n=== Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³Ø§Ø¹Øª ===")
    fetch_and_store_products(WATCH_API, WATCH_PRODUCTS, WATCH_COLORS, max_pages=2)

    # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø´Ø®ØµØ§Øª Ùˆ Ù†Ø¸Ø±Ø§Øª
    print("\n=== Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¢ÛŒÙÙˆÙ†â€ŒÙ‡Ø§ ===")
    fetch_full_product_data(IPHONE_PRODUCTS, IPHONE_COLORS, IPHONE_DETAILS_API, IPHONE_REVIEWS_API)

    print("\n=== Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø§Ø¹Øªâ€ŒÙ‡Ø§ ===")
    fetch_full_product_data(WATCH_PRODUCTS, WATCH_COLORS, WATCH_DETAILS_API, WATCH_REVIEWS_API)
